{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <h1 style=\"color:blue\">Mean Normalization</h1>\n",
    " <p>In Machine Learning we use to train a large number of data is required to Trained.For this purpose the machine learning algorithm need to be a  <b>Normalized data</b> for doing work or result correctly it is also called <b>feature scaling</b></p>\n",
    "    <h2 style=\"color:red\">Why do we do Mean Normalization?</h2>\n",
    "    <p>it is used to ensure that all data are in similar scale which means that all data are in similar range of data For example we have a dataset of range 0 to 5000 which we normalized between 0 to 1</p>\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly,We will create a numpy array between 0 to 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "X= np.random.randint(0,5001,size=(1000,20)) #create numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2340 2139 1273 ...    1 3018 4577]\n",
      " [ 783 3085 3286 ...  301 4578 2606]\n",
      " [4248  789 4991 ...  874 3470 1331]\n",
      " ...\n",
      " [4303 1985 4735 ... 4441  917 4860]\n",
      " [4494  339 3176 ...  752 4560 2280]\n",
      " [  43 1011  250 ... 4355  766 4008]]\n",
      "(1000, 20)\n"
     ]
    }
   ],
   "source": [
    "print(X)\n",
    "print(X.shape) #shape of the array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding the mean of columns and standard deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ave_cols =np.mean(X,axis=0)\n",
    "std_cols = np.std(X,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2433.346 2506.311 2501.829 2481.138 2474.177 2546.924 2507.64  2566.137\n",
      " 2522.041 2535.311 2482.447 2528.132 2492.034 2530.959 2529.598 2472.932\n",
      " 2497.201 2493.291 2472.629 2552.259]\n",
      "[1428.89262028 1451.14795327 1446.93955498 1459.49837443 1457.34867471\n",
      " 1445.49103914 1433.68357471 1443.30307705 1414.4772205  1430.8874506\n",
      " 1453.81471969 1421.1165     1419.07233461 1454.61800117 1451.31745059\n",
      " 1460.9686935  1473.57600096 1424.93262448 1458.87036277 1469.86212888]\n",
      "(20,)\n",
      "(20,)\n"
     ]
    }
   ],
   "source": [
    "print(ave_cols) #print the means colums\n",
    "print(std_cols) #print the standard deviation colums\n",
    "print(ave_cols.shape) \n",
    "print(std_cols.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we find mean Normalization through X_norm=(X-mean)/std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_norm=(X-ave_cols)/std_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.06532751 -0.25311754 -0.84926077 ... -1.74905884  0.37383102\n",
      "   1.37750403]\n",
      " [-1.15498252  0.39878015  0.54195146 ... -1.53852257  1.44315153\n",
      "   0.03656193]\n",
      " [ 1.26997227 -1.18341551  1.72030061 ... -1.13639829  0.68365979\n",
      "  -0.83086636]\n",
      " ...\n",
      " [ 1.30846361 -0.35924042  1.54337546 ...  1.36687796 -1.06632436\n",
      "   1.57003909]\n",
      " [ 1.44213356 -1.49351484  0.46592893 ... -1.22201637  1.43081322\n",
      "  -0.18522758]\n",
      " [-1.67286608 -1.03043318 -1.55627026 ...  1.30652423 -1.1698291\n",
      "   0.99039289]]\n",
      "(1000, 20)\n"
     ]
    }
   ],
   "source": [
    "print(X_norm)\n",
    "print(X_norm.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Data Sepration</h1>\n",
    "<ul>\n",
    "    <li>Training Set</li>\n",
    "    <li>A Cross Validation Set</li>\n",
    "    <li>A Test Set</li>\n",
    "</ul>\n",
    "<p>The dataset is usually divided such that 60% training set 20% cross validation set and 20% test set</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "row,column=X_norm.shape\n",
    "row_indices = np.random.permutation(row)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000,)\n"
     ]
    }
   ],
   "source": [
    "print(row_indices.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_norm[row_indices[0:600]]\n",
    "X_cross_val = X_norm[row_indices[600:800]]\n",
    "X_test = X_norm[row_indices[800:1000]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_training Set:\n",
      "  [[ 1.74866464 -0.69208036 -0.82438067 ... -0.80445277  1.56790559\n",
      "   0.5889947 ]\n",
      " [ 1.06141916  0.22374631  1.03471565 ... -0.20793334  0.34572709\n",
      "   1.37002033]\n",
      " [ 0.16632041  1.22157703  1.26831214 ...  1.74443967 -1.61263746\n",
      "  -0.24577747]\n",
      " ...\n",
      " [-0.60980509  0.97349757 -1.59773709 ...  1.4040727  -1.62497578\n",
      "  -0.01786494]\n",
      " [ 0.95854229 -0.6445318   1.71546281 ... -1.4522027  -0.98749624\n",
      "   1.2217071 ]\n",
      " [-1.1430852   1.50204464  1.08931364 ... -1.43465801  0.32242138\n",
      "   0.06445571]]\n",
      "X_Cross_Validation Set:\n",
      "  [[ 1.0194286   0.46080002 -0.64538218 ...  0.7493049   0.4245552\n",
      "   0.58287167]\n",
      " [-0.81765836  0.09832836 -1.09253285 ...  0.22787674  0.59454974\n",
      "   0.76452136]\n",
      " [ 1.47292664 -0.25105021 -0.64538218 ...  1.20195788 -0.58170282\n",
      "   0.43796012]\n",
      " ...\n",
      " [-0.5573169   1.50893573 -0.18233588 ...  0.32191627  1.26493145\n",
      "   0.88970317]\n",
      " [-0.51462649  0.40498214  0.57581604 ... -0.41706604 -0.0230514\n",
      "  -0.81249729]\n",
      " [-1.64977128 -0.51360097  1.4258861  ... -1.01919977 -0.1361526\n",
      "  -0.34714752]]\n",
      "X_Test set:\n",
      "  [[-0.78896481 -1.72161012  1.06858023 ...  1.59004641 -1.26990653\n",
      "   0.15834206]\n",
      " [-0.96112611  0.24648693 -0.42906353 ...  0.07418526  0.33750154\n",
      "  -1.085312  ]\n",
      " [-1.19347387 -0.10013521  0.72716997 ... -0.42548749 -0.23348819\n",
      "   1.11421403]\n",
      " ...\n",
      " [ 0.52813906 -0.0133074   0.70712767 ...  0.56684013 -1.02039841\n",
      "   1.33192152]\n",
      " [ 0.19711348  0.87702222  0.45832668 ...  1.01879133  1.03941449\n",
      "  -1.44861138]\n",
      " [-0.4950309  -0.50464255 -1.35308278 ...  0.36612889  0.77962445\n",
      "   1.41016015]]\n"
     ]
    }
   ],
   "source": [
    "print(\"X_training Set:\\n \",X_train)\n",
    "print(\"X_Cross_Validation Set:\\n \",X_cross_val)\n",
    "print(\"X_Test set:\\n \",X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
